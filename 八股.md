# Java相关

## Java 基础

### 静态方法为什么不能调用非静态成员?

1. 静态方法是属于类的，在类加载的时候就会分配内存，可以通过类名直接访问。而非静态成员属于实例对象，只有在对象实例化之后才存在，需要通过类的实例对象去访问。
2. 在类的非静态成员不存在的时候静态成员就已经存在了，此时调用在内存中还不存在的非静态成员，属于非法操作。
3. 调用静态方法无需创建对象，静态方法在访问本类的成员时，只允许访问静态成员（即静态成员变量和静态方法），不允许访问实例成员（即实例成员变量和实例方法），而实例方法不存在这个限制。

### 重载和重写的区别

**重载**就是同样的一个方法能够根据输入数据的不同，做出不同的处理(参数数量和类型都可以不一样，只要名字相同即可)

**重写**就是当子类继承自父类的相同方法，输入数据一样，但要做出有别于父类的响应时，你就要覆盖父类方法

* **构造方法**不能重写，但是可以重载，因为构造方法不能被继承
* **私有方法**不能重写，但是可以重载，因为私有方法不能被子类访问

### 基本数据类型

Java 中有 8 种基本数据类型，分别为：

- 6 种数字类型：
  - 4 种整数型：`byte`、`short`、`int`、`long`
  - 2 种浮点型：`float`、`double`
- 1 种字符类型：`char`
- 1 种布尔型：`boolean`

### 基本类型和包装类型的区别

- 包装类型不赋值就是 `null` ，而基本类型有默认值且不是 `null`。
- 包装类型可用于泛型，而基本类型不可以。
- 基本数据类型的局部变量存放在 Java 虚拟机栈中的局部变量表中，基本数据类型的成员变量（未被 `static` 修饰 ）存放在 Java 虚拟机的堆中。包装类型属于对象类型，我们知道几乎所有对象实例都存在于堆中。
- 相比于对象类型， 基本数据类型占用的空间非常小。

**为什么说是几乎所有对象实例呢？** 这是因为 HotSpot 虚拟机引入了 JIT 优化之后，会对对象进行逃逸分析，如果发现某一个对象并没有逃逸到方法外部，那么就可能通过标量替换来实现栈上分配，而避免堆上分配内存

### 包装类型的缓存机制

Java 基本数据类型的包装类型的大部分都用到了缓存机制来提升性能。`Byte`,`Short`,`Integer`,`Long` 这 4 种包装类默认创建了数值 **[-128，127]** 的相应类型的缓存数据，`Character` 创建了数值在 **[0,127]** 范围的缓存数据，`Boolean` 直接返回 `True` or `False`。

**所有整型包装类对象之间值的比较，全部使用 equals 方法比较**。

```java
Integer i1 = 40;
Integer i2 = new Integer(40);
System.out.println(i1==i2); // false
```

`i1` 直接使用的是缓存中的对象，而`Integer i2 = new Integer(40)` 会直接创建新的对象，== 比较的是地址，所以为 false。

### 接口和抽象类的共同点和区别

**共同点** ：

- 都不能被实例化。
- 都可以包含抽象方法。
- 都可以有默认实现的方法（Java 8 可以用 `default` 关键在接口中定义默认方法）。

**区别** ：

- 接口主要用于对类的行为进行约束，你实现了某个接口就具有了对应的行为。抽象类主要用于代码复用，强调的是所属关系（比如说我们抽象了一个发送短信的抽象类）。
- 接口可以继承多个父类，抽象类只能继承一个父类。
- 接口中的成员变量只能是 `public static final` 类型的，不能被修改且必须有初始值，而抽象类的成员变量默认 default，可在子类中被重新定义，也可被重新赋值。
- 接口侧重于实现封装（接口隐藏内部实现），抽象类侧重于提取共性。

### 深拷贝和浅拷贝的区别

- **浅拷贝**：浅拷贝会在堆上创建一个新的对象（区别于引用拷贝的一点），不过，如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址，也就是说拷贝对象和原对象共用同一个内部对象，B 复制 A，改变B，A也跟着改变。浅拷贝只复制某个对象的引用，而不复制对象本身，新旧对象还是共享同一块内存。
- **深拷贝** ：深拷贝会完全复制整个对象，包括这个对象所包含的内部对象，B 复制 A，改变B，A不会跟着改变。深拷贝会创造一个一摸一样的对象，新对象和原对象不共享内存，修改新对象不会改变原对对象。

### == 和 equals( ) 的区别

**`==`** 对于基本类型和引用类型的作用效果是不同的：

- 对于基本数据类型来说，`==` 比较的是值。
- 对于引用数据类型来说，`==` 比较的是对象的内存地址。

**`equals()`** 不能用于判断基本数据类型的变量，只能用来判断两个对象是否相等，如果没有对 equals 方法进行重写，则相当于 ==，比较的是引用类型的变量**所指向的对象的地址值**。

* 一般情况下，类会重写 equals 方法用来比较两个对象的内容是否相等。比如 String 类中的 equals() 是被重写了，比较的是**对象的值**。

### String、StringBuffer 和 StringBuilder

**可变性**

`String` 是不可变的。

原因：

1. 保存字符串的数组被 `final` 修饰且为私有的，并且`String` 类没有提供/暴露修改这个字符串的方法。
2. `String` 类被 `final` 修饰导致其不能被继承，进而避免了子类破坏 `String` 不可变。

`StringBuilder` 与 `StringBuffer` 都继承自 `AbstractStringBuilder` 类，在 `AbstractStringBuilder` 中也是使用字符数组保存字符串，不过没有使用 `final` 和 `private` 关键字修饰，最关键的是这个 `AbstractStringBuilder` 类还提供了很多修改字符串的方法比如 `append` 方法。

**线程安全性**

`String` 中的对象是不可变的，也就可以理解为常量，线程安全。`AbstractStringBuilder` 是 `StringBuilder` 与 `StringBuffer` 的公共父类，定义了一些字符串的基本操作，如 `expandCapacity`、`append`、`insert`、`indexOf` 等公共方法。`StringBuffer` 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。`StringBuilder` 并没有对方法进行加同步锁，所以是非线程安全的。

**性能**

每次对 `String` 类型进行改变的时候，都会生成一个新的 `String` 对象，然后将指针指向新的 `String` 对象。`StringBuffer` 每次都会对 `StringBuffer` 对象本身进行操作，而不是生成新的对象并改变对象引用。相同情况下使用 `StringBuilder` 相比使用 `StringBuffer` 仅能获得 10%~15% 左右的性能提升，但却要冒多线程不安全的风险。

## 容器

###  List, Set, Queue, Map 四者的区别

- `List`(对付顺序的好帮手): 存储的元素是有序的、可重复的。
- `Set`(注重独一无二的性质): 存储的元素是无序的、不可重复的。
- `Queue`(实现排队功能的叫号机): 按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。
- `Map`(用 key 来搜索的专家): 使用键值对（key-value）存储，类似于数学上的函数 y=f(x)，"x" 代表 key，"y" 代表 value，key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。

### HashMap 和 Hashtable 的区别

* **线程是否安全：** `HashMap` 是非线程安全的，`Hashtable` 是线程安全的，因为 `Hashtable` 内部的方法基本都经过`synchronized` 修饰。（如果你要保证线程安全的话就使用 `ConcurrentHashMap` 吧！）；
* **效率：** 因为线程安全的问题，`HashMap` 要比 `Hashtable` 效率高一点。另外，`Hashtable` 基本被淘汰，不要在代码中使用它；
* **对 Null key 和 Null value 的支持：** `HashMap` 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；Hashtable 不允许有 null 键和 null 值，否则会抛出 `NullPointerException`；
* **初始容量大小和每次扩充容量大小的不同 ：** ① 创建时如果不指定容量初始值，`Hashtable` 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。`HashMap` 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。② 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 `HashMap` 会将其扩充为 2 的幂次方大小（`HashMap` 中的`tableSizeFor()`方法保证，下面给出了源代码）。也就是说 `HashMap` 总是使用 2 的幂作为哈希表的大小，后面会介绍到为什么是 2 的幂次方；
* **底层数据结构：** JDK1.8 以后的 `HashMap` 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。

### HashSet 如何检查重复

当你把对象加入`HashSet`时，`HashSet` 会先计算对象的`hashcode`值来判断对象加入的位置，同时也会与其他加入的对象的 `hashcode` 值作比较，如果没有相符的 `hashcode`，`HashSet` 会假设对象没有重复出现。但是如果发现有相同 `hashcode` 值的对象，这时会调用`equals()`方法来检查 `hashcode` 相等的对象是否真的相同。如果两者相同，`HashSet` 就不会让加入操作成功。

### HashMap

* JDK 1.8 之前，HashMap 底层是数组和链表结合，JDK 1.8 之后变为数组和链表以及红黑树结合。
* HashMap 通过 key 的 hashCode 经过**扰动函数**（二次哈希，为了综合高位数据，让哈希分布更为均匀）处理过后得到 hash 值，然后通过 `(n - 1) & hash` 即 hash % n 来判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突（JDK 1.7 之前）。
* JDK 1.8 之后，当链表长度大于阈值（默认为 8）时，会首先调用 `treeifyBin()`方法。这个方法会根据 HashMap 数组来决定是否转换为红黑树。只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作，以减少搜索时间。否则，就是只是执行 `resize()` 方法对数组扩容。
* 链表 -> 红黑树，先判断数组长度是否大于或者等于 64，不是则先进行扩容，是则再判断链表长度是否大于阈值（默认为 8），若大于则树化。
* 扩容：当链表总长度大于数组长度 * 加载因子，则选择扩容。
* **变为红黑树的链表阈值为何默认是8？**因为红黑树是用来避免 Dos 攻击，是极端的情况，一般不会转变，在负载因子0.75 的情况下。长度超过 8 的链表几率很小，所以选择 8 是为了让树化的几率变小。
* **数组容量为何是 2 的 n 次幂？**取模时可以用位运算`(n - 1) & hash` 代替 hash % n，效率更高；扩容时计算新的位置效率也更高，追求性能
* **加载因子为何默认是 0.75f ？**在空间占用和查询时间之间取得较好的权衡
* 1.7 put 为头插法，在扩容过程中会发生**死链**（并发下的 Rehash 会造成元素之间会形成一个循环链表）问题，大于等于阈值且没有空位才扩容 1.8 put 为尾插法，大于阈值就扩容
* **使用 HashMap 的注意事项**
  * 首先了解过其底层的都知道，HashMap 有个扩容机制，是比较耗时的，所以为了减少扩容次数，在知道要存放多少元素的前提下最好指定 HashMap 的链表初始大小
  * 为了减少链表的碰撞次数，尽可能的选择不可变的类型作为 Key，以为其不可变形，其 HashCode 的值也会不可变。如 String 类型
  * 使用 HashMap 做缓存时，因为其线程不安全特性，最好使用 ConcurrentHashMap 代替
  * key 相同会覆盖之前的数据，因为其 key 的 hashcode 相同会向其 index 所对应的 entry 进行 equals 相同则覆盖

### ArrayList 和 LinkedList

* 都不保证线程安全
* ArrayList 底层为 Object 数组，LinkedList 底层为 双向链表（JDK1.6 之前为循环链表，JDK1.7 取消了循环）
* LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于`get(int index)`方法)
* ArrayList 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）
* **ArrayList 扩容机制**
  * Arrlist扩容是原来的数组长度1.5倍，源码上是对原来的数组长度向右位移一位（就是除以2）然后加上原来的数组长度。然后减去原来的数组判断是否小与 0 如果小与就使用原来的数组长度
  * 数组进行扩容时，会将老数据中得元素重新拷贝一份道新的数组中，每次数组容量得增长大于时原用量得1.5倍，拷贝的代价是很高的，所以在实际使用中，我们应指定容量，避免数组扩容的发生

## 并发编程

### 线程和进程

* 进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程，是系统进行**资源分配的基本单位**。
* 线程是属于进程的，是一个基本的 CPU 执行单元，是程序执行流的最小单元。线程是进程中的一个实体，是系统**独立调度的基本单位**，线程本身不拥有系统资源，只拥有一点在运行中必不可少的资源，但它可与同属一个进程的其他线程共享进程所拥有的全部资源。
* 关系：
  * 一个进程中可以有多个线程，多个线程共享进程的**堆**和**方法区**，每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**。
  * 线程执行开销小，但不利于资源的管理和保护；进程执行开销大，但有利于资源的管理和保护。

### 进程间的通信方式

* 同一台计算机的进程通信称为 IPC（Inter-process communication）
  * 信号量：信号量是一个计数器，用于多进程对共享数据的访问，解决同步相关的问题并避免竞争条件
  * 共享存储：多个进程可以访问同一块内存空间，需要使用信号量用来同步对共享存储的访问
  * 管道通信：管道是用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件 pipe 文件，该文件同一时间只允许一个进程访问，所以只支持**半双工通信**
    * 匿名管道（Pipes）：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信
    * 命名管道（Names Pipes）：以磁盘文件的方式存在，可以实现本机任意两个进程通信，遵循 FIFO
  * 消息队列：内核中存储消息的链表，由消息队列标识符标识，能在不同进程之间提供**全双工通信**，对比管道：
    * 匿名管道存在于内存中的文件；命名管道存在于实际的磁盘介质或者文件系统；消息队列存放在内核中，只有在内核重启（操作系统重启）或者显示地删除一个消息队列时，该消息队列才被真正删除
    * 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收

* 不同计算机之间的进程通信，需要通过网络，并遵守共同的协议，例如 HTTP
  * 套接字：与其它通信机制不同的是，可用于不同机器间的互相通信

### 线程间的通信方式

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：

1. **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
2. **信号量(Semaphore)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
3. **事件(Event)** ：Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。

### 并发和并行

* **并发**：两个及两个以上的作业在同一 **时间段** 内执行，交替执行
* **并行**：两个及两个以上的作业在同一 **时刻** 执行，同时执行

### 创建线程的三种方式

* 线程池

* 利用 Thread 类创建一个对象

  ```java
  Thread t = new Thread();
  t.start();
  ```

  * 优点：编码简单
  * 缺点：线程类已经继承了 Thread 类无法继承其他类了，功能不能通过继承拓展（单继承的局限性）

* 利用 Runnable 类创建一个对象

  ```java
  // 匿名内部类
  Runnable runnable = new Runnable() {
  	@Override
  	public void run() {
  		System.out.println("t1线程在运行");
  	}
  Thread t1 = new Thread(runnable, "t1");
  t1.start();
  // Lambda 表达式
  Runnable runnable = () -> System.out.println("t1线程在运行");
  Thread t1 = new Thread(runnable, "t1");
  t1.start();
  ```

  * 缺点：代码复杂一点。
  * 优点：

    1. 线程任务类只是实现了 Runnable 接口，可以继续继承其他类，避免了单继承的局限性
    2. 同一个线程任务对象可以被包装成多个线程对象
    3. 适合多个线程去共享同一个资源
    4. 实现解耦操作，线程任务代码可以被多个线程共享，线程任务代码和线程独立
    5. 线程池可以放入实现 Runnable 或 Callable 线程任务对象

* 实现 Callable 接口

  ```java
  Callable<String> integerCallable = () -> Thread.currentThread().getName();
  FutureTask<String> task = new FutureTask<>(integerCallable);
  Thread thread = new Thread(task);
  thread.start();
  try {
      String s = task.get();
      System.out.println(s);
  } catch (InterruptedException | ExecutionException e) {
      throw new RuntimeException(e);
  }
  ```

* 实现 Runnable 接口和 Callable 接口的区别

  **`Runnable` 接口** 不会返回结果或抛出检查异常，但是 **`Callable` 接口** 可以。所以，如果任务不需要返回结果或抛出异常推荐使用 **`Runnable` 接口** ，这样代码看起来会更加简洁。

### 线程的状态和生命周期

线程由生到死的完整过程（生命周期）：当线程被创建并启动以后，既不是一启动就进入了执行状态，也不是一直处于执行状态，在 API 中 `java.lang.Thread.State` 这个枚举中给出了六种线程状态：

| 线程状态                   | 导致状态发生条件                                             |
| -------------------------- | ------------------------------------------------------------ |
| NEW（新建）                | 线程刚被创建，但是并未启动，还没调用 start 方法，只有线程对象，没有线程特征 |
| Runnable（可运行）         | 线程可以在 Java 虚拟机中运行的状态，可能正在运行自己代码，也可能没有，这取决于操作系统处理器，调用了 t.start() 方法：就绪（经典叫法） |
| Blocked（锁阻塞）          | 当一个线程试图获取一个对象锁，而该对象锁被其他的线程持有，则该线程进入 Blocked 状态；当该线程持有锁时，该线程将变成 Runnable 状态 |
| Waiting（无限等待）        | 一个线程在等待另一个线程执行一个（唤醒）动作时，该线程进入 Waiting 状态，进入这个状态后不能自动唤醒，必须等待另一个线程调用 notify 或者 notifyAll 方法才能唤醒 |
| Timed Waiting （计时等待） | 有几个方法有超时参数，调用将进入 Timed Waiting 状态，这一状态将一直保持到超时期满或者接收到唤醒通知。带有超时参数的常用方法有 Thread.sleep 、Object.wait |
| Teminated（被终止）        | run 方法正常退出而死亡，或者因为没有捕获的异常终止了 run 方法而死亡 |

* NEW → RUNNABLE：当调用 t.start() 方法时，由 NEW → RUNNABLE

* RUNNABLE ←→ WAITING：

  * 调用 obj.wait() 方法时

    调用 obj.notify()、obj.notifyAll()、t.interrupt()：

    * 竞争锁成功，t 线程从 WAITING → RUNNABLE
    * 竞争锁失败，t 线程从 WAITING → BLOCKED

  * 当前线程调用 t.join() 方法，注意是当前线程在 t 线程对象的监视器上等待

  * 当前线程调用 LockSupport.park() 方法

* RUNNABLE ←→ TIMED_WAITING：调用 obj.wait(long n) 方法、当前线程调用 t.join(long n) 方法、当前线程调用 Thread.sleep(long n)

* RUNNABLE ←→ BLOCKED：t 线程用 synchronized(obj) 获取了对象锁时竞争失败

### 上下文切换

线程在执行过程中会有自己的运行条件和状态（也称上下文），出现如下情况的时候，线程会从占用 CPU 状态中退出。

- 主动让出 CPU，比如调用了 `sleep()`, `wait()` 等。
- 时间片用完，因为操作系统要防止一个线程或者进程长时间占用CPU导致其他线程或者进程饿死。
- 调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。
- 被终止或结束运行

这其中前三种都会发生线程切换，线程切换意味着需要保存当前线程的上下文，留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的 **上下文切换**。

### 死锁以及避免死锁

线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。比如线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。

Java 死锁产生的四个必要条件：

1. 互斥条件，即当资源被一个线程使用（占有）时，别的线程不能使用
2. 不可剥夺条件，资源请求者不能强制从资源占有者手中夺取资源，资源只能由资源占有者主动释放
3. 请求和保持条件，即当资源请求者在请求其他的资源的同时保持对原有资源的占有
4. 循环等待条件，即存在一个等待循环队列：p1 要 p2 的资源，p2 要 p1 的资源，形成了一个等待环路

四个条件都成立的时候，便形成死锁。死锁情况下打破上述任何一个条件，便可让死锁消失，避免死锁要注意加锁顺序

### sleep() 和 wait() 方法区别和共同点

共同点：

* 都是让线程暂时放弃 CPU 的使用权，进入阻塞状态

区别：

* sleep 是 Thread 的静态方法，wait 是 Object 的成员方法，每个对象都有
* `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify() `或者 `notifyAll()` 方法。`sleep() `方法执行完成后，线程会自动苏醒
* wait 方法的调用必须先获取wait对象的锁，而 sleep 则无此限制。`sleep()` 方法并不会释放对象的锁，而 `wait()` 方法执行后会释放对象锁 

### run 和 start 方法

new 一个 Thread，线程进入了新建状态。调用 `start()`方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 `start()` 会执行线程的相应准备工作，然后自动执行 `run()` 方法的内容，这是真正的多线程工作。 但是，直接执行 `run()` 方法，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

总结： 调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行。

### 悲观锁

顾名思义，悲观锁是基于一种悲观的态度类来防止一切数据冲突，它是以一种预防的姿态在修改数据之前把数据锁住，然后再对数据进行读写，在它释放锁之前任何人都不能对其数据进行操作，直到前面一个人把锁释放后下一个人数据加锁才可对数据进行加锁，然后才可以对数据进行操作。

#### synchronized

##### synchronized 关键字使用的方法

* **修饰实例方法:** 作用于当前对象实例加锁，进入同步代码前要获得 **当前对象实例的锁**
* **修饰静态方法:** 也就是给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 **当前 class 的锁**。因为静态成员不属于任何一个实例对象，是类成员（ *static 表明这是该类的一个静态资源，不管 new 了多少个对象，只有一份*）。所以，如果一个线程 A 调用一个实例对象的非静态 `synchronized` 方法，而线程 B 需要调用这个实例对象所属类的静态 `synchronized` 方法，是允许的，不会发生互斥现象，**因为访问静态 `synchronized` 方法占用的锁是当前类的锁，而访问非静态 `synchronized` 方法占用的锁是当前实例对象锁**。
* **修饰代码块** ：指定加锁对象，对给定对象/类加锁。`synchronized(this|object)` 表示进入同步代码库前要获得**给定对象的锁**。`synchronized(类.class)` 表示进入同步代码前要获得 **当前 class 的锁**

##### synchronized 关键字修饰非静态方法和修饰静态方法有什么区别？

- synchronized 修饰非静态方法，实际上是对调用该方法的对象加锁，俗称“对象锁”。
- synchronized 修饰静态方法，实际上是对该类对象加锁，俗称“类锁”。

##### synchronized 关键字的底层原理

* Monitor 被翻译为监视器或管程，每个 Java 对象都可以关联一个 Monitor 对象，Monitor 也是 class，其**实例存储在堆中**，如果使用 synchronized 给对象上锁（重量级）之后，该对象头的 Mark Word 中就被设置指向 Monitor 对象的指针，这就是重量级锁。
* 工作流程
  * 开始时 Monitor 中 Owner 为 null
  * 当 Thread-2 执行 synchronized(obj) 就会将 Monitor 的所有者 Owner 置为 Thread-2，Monitor 中只能有一个 Owner，**obj 对象的 Mark Word 指向 Monitor**，把**对象原有的 MarkWord 存入线程栈中的锁记录**中（轻量级锁部分详解）
  * 在 Thread-2 上锁的过程，Thread-3、Thread-4、Thread-5 也执行 synchronized(obj)，就会进入 EntryList BLOCKED（双向链表：阻塞对列，非公平的）
  * Thread-2 执行完同步代码块的内容，根据 obj 对象头中 Monitor 地址寻找，设置 Owner 为空，把线程栈的锁记录中的对象头的值设置回 MarkWord
  * 唤醒 EntryList 中等待的线程来竞争锁，竞争是**非公平的**，如果这时有新的线程想要获取锁，可能直接就抢占到了，阻塞队列的线程就会继续阻塞
  * WaitSet 中的 Thread-0，是以前获得过锁，但条件不满足进入 WAITING 状态的线程（wait-notify 机制）

##### synchronized 锁升级

* **synchronized 是可重入、不公平的重量级锁**，所以可以对其进行优化，无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁，随着竞争的增加，只能锁升级，不能降级
* 偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程之后重新获取该锁不再需要同步操作
* 一个对象有多个线程要加锁，但加锁的时间是错开的（没有竞争），可以使用轻量级锁来优化，轻量级锁对使用者是透明的（不可见）**可重入锁**：线程可以进入任何一个它已经拥有的锁所同步着的代码块，可重入锁最大的作用是**避免死锁**
* 在尝试加轻量级锁的过程中，CAS 操作无法成功，可能是其它线程为此对象加上了轻量级锁（有竞争），这时需要进行锁膨胀，将轻量级锁变为**重量级锁**
* **自旋锁**：重量级锁竞争时，尝试获取锁的线程不会立即阻塞，可以使用**自旋**（默认 10 次）来进行优化，采用循环的方式去尝试获取锁

#### Lock

##### synchronized 和 ReentrantLock 的区别

* 锁的实现：synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的
* 性能：新版本 Java 对 synchronized 进行了很多优化，synchronized 与 ReentrantLock 大致相同
* 使用：ReentrantLock 需要手动解锁，synchronized 执行完代码块自动解锁
* 可中断：ReentrantLock 可中断，而 synchronized 不行
* 公平锁：公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁
  * ReentrantLock 可以设置公平锁，synchronized 中的锁是非公平的
  * 不公平锁的含义是阻塞队列内公平，队列外非公平
* 锁超时：尝试获取锁，超时获取不到直接放弃，不进入阻塞队列
  * ReentrantLock 可以设置超时时间，synchronized 会一直等待
* 锁绑定多个条件：一个 ReentrantLock 可以同时绑定多个 Condition 对象，即条件变量
* 两者都是可重入锁

#### volatile

* Java 内存模型抽象了线程和主内存之间的关系，当前的 Java 内存模型下，线程可以把变量保存**本地内存**（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成**数据的不一致**。要解决这个问题，就需要把变量声明为 **`volatile`** ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。

* volatile 是 Java 虚拟机提供的**轻量级**的同步机制（三大特性）

  - **保证可见性**
  - **不保证原子性**
  - **保证有序性**（禁止指令重排）

* 并发编程的三个重要特性

  * **原子性** : 一次操作或者多次操作，要么所有的操作全部都得到执行并且不会受到任何因素的干扰而中断，要么都不执行。`synchronized` 可以保证代码片段的原子性。
  * **可见性** ：当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。`volatile` 关键字可以保证共享变量的可见性。
  * **有序性** ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。`volatile` 关键字可以禁止指令进行重排序优化。

#### happens - before 原则

happens-before 规定了对共享变量的写操作对其它线程的读操作可见，它是可见性与有序性的一套规则总结

* 线程解锁 m 之前对变量的写，对于接下来对 m 加锁的其它线程对该变量的读可见
* 线程对 volatile 变量的写，对接下来其它线程对该变量的读可见
* 线程 start() 前对变量的写，对该线程开始后对该变量的读可见
* 线程结束前对变量的写，对其它线程得知它结束后的读可见（比如其它线程调用 t1.isAlive() 或 t1.join()等待 它结束）
* 线程 t1 打断 t2（interrupt）前对变量的写，对于其他线程得知 t2 被打断后对变量的读可见（通过 t2.interrupted 或 t2.isInterrupted）
* 对变量默认值（0，false，null）的写，对其它线程对该变量的读可见

### 乐观锁

对于并发操作产生的线程安全问题持乐观态度，认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据，如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则执行其他操作，如报错或自动重试。

#### cas

* Compare-And-Set 比较并交换，对比版本号，如果修改了版本号就变了交换，版本号一样就交换；比较当前工作内存中的值和主物理内存中的值，如果相同则执行规定操作，否则继续比较直到主内存和工作内存的值一致为止
* CAS 特点：

  * CAS 体现的是**无锁并发、无阻塞并发**，线程不会陷入阻塞，线程不需要频繁切换状态（上下文切换，系统调用）
  * CAS 是基于乐观锁的思想
* CAS 缺点：

  - 循环时间长，开销大，因为执行的是循环操作，如果比较不成功一直在循环，最差的情况某个线程一直取到的值和预期值都不一样，就会无限循环导致饥饿，**使用 CAS 线程数不要超过 CPU 的核心数**
  - 只能保证一个共享变量的原子操作
    - 对于一个共享变量执行操作时，可以通过循环 CAS 的方式来保证原子操作
    - 对于多个共享变量操作时，循环 CAS 就无法保证操作的原子性，这个时候**只能用锁来保证原子性**
  - ABA 问题：当进行获取主内存值时，该内存值在写入主内存时已经被修改了 N 次，但是最终又改成原来的值，其他线程先把 A 改成 B 又改回 A，主线程**仅能判断出共享变量的值与最初值 A 是否相同**，不能感知到这种从 A 改为 B 又 改回 A 的情况，这时 CAS 虽然成功，但是过程存在问题

### ThreadLocal

* `ThreadLocal`类主要解决的就是让每个线程绑定自己的值，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据，可以使用 `get（）` 和 `set（）` 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。
* 底层原理
  * JDK8 以前：每个 ThreadLocal 都创建一个 Map，然后用线程作为 Map 的 key，要存储的局部变量作为 Map 的 value，达到各个线程的局部变量隔离的效果。这种结构会造成 Map 结构过大和内存泄露，因为 Thread 停止后无法通过 key 删除对应的数据
  * JDK8 以后：每个 Thread 维护一个 ThreadLocalMap，这个 Map 的 key 是 ThreadLocal 实例本身，value 是真正要存储的值
* **ThreadLocal 内存泄漏问题**：`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用，而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用`remove()`方法
* **ThreadLocal 不支持继承性**
  * 同一个 ThreadLocal 变量在父线程中设置值后，在子线程是取不到的
  * 利用 InheritableThreadLocal 类来解决继承性，当父线程创建子线程时，构造函数会把父线程中inheritableThreadLocals 变量里面的本地变量复制一份保存到子线程的 inheritableThreadLocals 变量里面
* ThreadLocal 和 Request
  * Request 根据 KEY 存取值、一个 Request 可以存多个值，ThreadLocal 只能存一个值，ThreadLocal 的 get 和set 方法没有参数 KEY
  * Request 使用在表示层、一般在 Action 和 Servlet 中使用，ThreadLocal 在什么地方都可以、一般用在框架基类中比较多、比如存放当前的数据库连接等
* 项目中的 UserHolder 类用到了 ThreadLocal 

### 线程池

**线程池**提供了一种限制和管理资源（包括执行一个任务）的方式。 每个**线程池**还维护一些基本统计信息，例如已完成任务的数量。

* **线程池的好处**：

  - **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
  - **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。
  - **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

* 线程池创建方式

  * 通过构造方法 ThreadPoolExecutor 构造
  * 通过 Executor 框架的工具类 Executors 来实现
    * **FixedThreadPool** ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。
    * **SingleThreadExecutor：** 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
    * **CachedThreadPool：** 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。

* **ThreadPoolExecutor 类的参数分析**

  * **`corePoolSize` :** 核心线程数定义了最小可以同时运行的线程数量。
  * **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
  * **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。
  * **`keepAliveTime`**：当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；
  * **`unit`** ：`keepAliveTime` 参数的时间单位。
  * **`threadFactory`** ：线程工厂，创建新线程时用到，可以为线程创建时起名字
  * **`handler`** ：拒绝策略：如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时的策略
    * AbortPolicy：让调用者抛出 RejectedExecutionException 异常，**默认策略**
    * CallerRunsPolicy：让调用者运行的调节机制(**调用执行自己的线程运行任务，也就是直接在调用`execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务**)，将某些任务回退到调用者，从而降低新任务的流量
    * DiscardPolicy：直接丢弃任务，不予任何处理也不抛出异常
    * DiscardOldestPolicy：放弃队列中最早的任务，把当前任务加入队列中尝试再次提交当前任务

* 原理

  ![图解线程池实现原理](https://javaguide.cn/assets/%E5%9B%BE%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.2b9eb21a.png)

* 提交方式 execute() 方法和 submit() 方法的区别

  * `execute()`方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否
  * `submit()`方法用于提交需要返回值的任务，线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功，并且可以通过 `Future` 的 `get()`方法来获取返回值，`get()`方法会阻塞当前线程直到任务完成，而使用 `get(long timeout, TimeUnit unit)`方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完

* 项目中异步下单优惠券时用到过 SingleThreadExecutor 和 FixedThreadPool

### AQS

AbstractQueuedSynchronizer，是阻塞式锁和相关的同步器工具的框架，许多同步类实现都依赖于该同步器

* **原理**：

  * 如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置锁定状态
  * 请求的共享资源被占用，AQS 用 CLH 队列实现线程阻塞等待以及被唤醒时锁分配的机制，将暂时获取不到锁的线程加入到队列中
  * CLH 是一种基于双向链表的**高性能、公平的自旋锁**，AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点（Node）来实现锁的分配
  * AQS 使用一个 int 成员变量 state 来表示同步状态，通过内置的 FIFO 队列来完成获取资源线程的排队工作。AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。

* AQS 定义两种资源共享方式

  * **Exclusive**（独占）

    只有一个线程能执行，如 `ReentrantLock`。又可分为公平锁和非公平锁，`ReentrantLock` 同时支持两种锁，下面以 `ReentrantLock` 对这两种锁的定义做介绍：

    - **公平锁** ：按照线程在队列中的排队顺序，先到者先拿到锁
    - **非公平锁** ：当线程要获取锁时，先通过两次 CAS 操作去抢锁，如果没抢到，当前线程再加入到队列中等待唤醒。

  * **Share**（共享）

    多个线程可同时执行，如 `Semaphore/CountDownLatch`。

#### AQS 组件

- **`Semaphore`(信号量)-允许多个线程同时访问：** `synchronized` 和 `ReentrantLock` 都是一次只允许一个线程访问某个资源，`Semaphore`(信号量)可以指定多个线程同时访问某个资源。
- **`CountDownLatch `（倒计时器）：** `CountDownLatch` 是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。
- **`CyclicBarrier`(循环栅栏)：** `CyclicBarrier` 和 `CountDownLatch` 非常类似，它也可以实现线程间的技术等待，但是它的功能比 `CountDownLatch` 更加复杂和强大。主要应用场景和 `CountDownLatch` 类似。`CyclicBarrier` 的字面意思是可循环使用（`Cyclic`）的屏障（`Barrier`）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。`CyclicBarrier` 默认的构造方法是 `CyclicBarrier(int parties)`，其参数表示屏障拦截的线程数量，每个线程调用 `await()` 方法告诉 `CyclicBarrier` 我已经到达了屏障，然后当前线程被阻塞。

### ConcurrentHashMap

* Java7 中 ConcurrentHashMap 使用的分段锁，也就是每一个 Segment 上同时只有一个线程可以操作，每一个 Segment 都是一个类似 HashMap 数组的结构，它可以扩容，它的冲突会转化为链表。但是 Segment 的个数一但初始化就不能改变。
* Java8 中的 ConcurrentHashMap 使用的 Synchronized 锁加 CAS 的机制。结构也由 Java7 中的 **Segment 数组 + HashEntry 数组 + 链表** 进化成了 **Node 数组 + 链表 / 红黑树**，Node 是类似于一个 HashEntry 的结构。它的冲突再达到一定大小时会转化成红黑树，在冲突小于一定数量时又退回链表。
* `synchronized` 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，效率又提升 N 倍。

## 框架

### Spring, Spring MVC, Spring Boot 之间的关系

* Spring 包含了多个功能模块（上面刚刚提高过），其中最重要的是 Spring-Core（主要提供 IoC 依赖注入功能的支持） 模块， Spring 中的其他模块（比如 Spring MVC）的功能实现基本都需要依赖于该模块。
* Spring MVC 是 Spring 中的一个很重要的模块，主要赋予 Spring 快速构建 MVC 架构的 Web 程序的能力。MVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码。
* Spring Boot 只是简化了配置，如果你需要构建 MVC 架构的 Web 程序，你还是需要使用 Spring MVC 作为 MVC 框架，只是说 Spring Boot 帮你简化了 Spring MVC 的很多配置，真正做到开箱即用。

### Spring 是如何解决循环依赖的

Spring在实例化一个bean的时候，是首先递归的实例化其所依赖的所有bean，直到某个bean没有依赖其他bean，此时就会将该实例返回，然后反递归的将获取到的bean设置为各个上层bean的属性的

### Spring IOC & AOP

#### IOC

* **IoC（Inverse of Control:控制反转）** 是一种设计思想，而不是一个具体的技术实现。IoC 的思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。不过， IoC 并非 Spring 特有，在其他语言中也有应用。
* 将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来。 IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。
* 如何实现一个 IOC 容器

  * 配置文件配置包扫描路径
  * 递归包扫描获取 .class 文件
  * 反射、确定需要交给 IOC 管理的类
  * 对需要注入的类进行依赖注入

  - 配置文件中指定需要扫描的包路径
  - 定义一些注解，分别表示访问控制层、业务服务层、数据持久层、依赖注入注解、获取配置文件注解
  - 从配置文件中获取需要扫描的包路径，获取到当前路径下的信息，我们将当前路径下所有以 .class 结尾的文件添加到一个 set 集合中进行存储
  - 遍历这个 set 集合，获取在类上有指定注解的类，并将其交给 IOC 容器，定义一个安全的 Map 用来存储这些对象
  - 遍历这个 IOC 容器，获取到每一个类的实例，判断里面是否有依赖其他的类的实例，然后进行递归注入

#### AOP

* AOP 即面向切面编程，简单地说就是将代码中重复的部分抽取出来，在需要执行的时候使用动态代理技术，在不修改源码的基础上对方法进行增强。
* 常用场景包括权限认证、自动缓存、错误处理、日志、调试和事务等。

### SpringBoot 自动装配

SpringBoot 所有⾃动配置类都是在启动的时候进⾏扫描并加载，通过 spring.factories 可以找到⾃动配置类的路径，但是不是所有存在于spring,factories中的配置都进⾏加载，⽽是通过 @ConditionalOnClass 注解进⾏判断条件是否成⽴（只要导⼊相应的 stater，条件就能成⽴），如果条件成⽴则加载配置类，否则不加载该配置类
自动装配过程：

* SpringBoot 在启动的时候从类路径下的 META-INF/spring.factories 中获取 EnableAutoConfiguration 指定的值
* 将这些值作为⾃动配置类导⼊容器 ，⾃动配置类就⽣效 ，帮我们进⾏⾃动配置⼯作；以前我们需要⾃⼰配置的东西 ，⾃动配置类都帮我们解决了
* 整个 J2EE 的整体解决⽅案和⾃动配置都在 springboot-autoconfigure 的 jar 包中；
* 它将所有需要导⼊的组件以全类名的⽅式返回 ， 这些组件就会被添加到容器中 ；
* 它会给容器中导⼊⾮常多的⾃动配置类 （xxxAutoConfiguration）, 就是给容器中导⼊这个场景需要的所有组件 ，并配置好这些组件 ；

Spring Boot 通过`@EnableAutoConfiguration`开启自动装配，通过 SpringFactoriesLoader 最终加载`META-INF/spring.factories`中的自动配置类实现自动装配，自动配置类其实就是通过`@Conditional`按需加载的配置类，想要其生效必须引入`spring-boot-starter-xxx`包实现起步依赖

### 常用注解

* 我们一般使用 `@Autowired` 注解让 Spring 容器帮我们自动装配 bean。要想把类标识成可用于 `@Autowired` 注解自动装配的 bean 的类,可以采用以下注解实现：
  - `@Component` ：通用的注解，可标注任意类为 `Spring` 组件。如果一个 Bean 不知道属于哪个层，可以使用`@Component` 注解标注。
  - `@Repository` : 对应持久层即 Dao 层，主要用于数据库相关操作。
  - `@Service` : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。
  - `@Controller` : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面。
* `@RestController`注解是`@Controller`和`@ResponseBody`的合集,表示这是个控制器 bean,并且是将函数的返回值直接填入 HTTP 响应体中,是 REST 风格的控制器。单独使用 `@Controller` 不加 `@ResponseBody`的话一般是用在要返回一个视图的情况，这种情况属于比较传统的 Spring MVC 的应用，对应于前后端不分离的情况。`@Controller` +`@ResponseBody` 返回 JSON 或 XML 形式数据
* `@Scope`声明 Spring Bean 的作用域，**四种常见的 Spring Bean 的作用域：**
  - singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。
  - prototype : 每次请求都会创建一个新的 bean 实例。
  - request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。
  - session : 每一个 HTTP Session 会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。
* `@Configuration`声明配置类
* HTTP 请求类型
  * **GET** ：请求从服务器获取特定资源。举个例子：`GET /users`（获取所有学生）
  * **POST** ：在服务器上创建一个新的资源。举个例子：`POST /users`（创建学生）
  * **PUT** ：更新服务器上的资源（客户端提供更新后的整个资源）。举个例子：`PUT /users/12`（更新编号为 12 的学生）
  * **DELETE** ：从服务器删除特定的资源。举个例子：`DELETE /users/12`（删除编号为 12 的学生）
  * **PATCH** ：更新服务器上的资源（客户端提供更改的属性，可以看做作是部分更新），使用的比较少
* **@Transactional 注解**：加在方法上，保持该方法的原子性
  * 不生效的场景：
    * 用在非 public 方法：@Transactional 是基于动态代理的，Spring 的代理工厂在启动时会扫描所有的类和方法，并检查方法的修饰符是否为 public，非 public 时不会获取 @Transactional 的属性信息，这时@Transactional 的动态代理对象为空
    * 同一个类中，非 @Transactional 方法调用 @Transactional 方法：类内部方法的调用是通过 this 调用的，不会使用动态代理对象，事务不会回滚
    * Spring 是根据抛出的异常来回滚的，如果异常被捕获了没有抛出的话，事务就不会回滚
    * rollbackFor 属性设置不对：Spring 默认抛出 unchecked 异常或 Error 时才会回滚事务，要想其他类型异常也回滚则需要设置 rollbackFor 属性的值
* @Component 和 @Bean
  * @Component 和 @Bean 都是声明一个bean交给spring管理
  * 作用对象不同: @Component 注解作用于类，而@Bean注解作用于方法
  * @Component 通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean，@Bean 告诉了Spring这是某个类的示例，当我需要用它的时候还给我
  * @Bean 注解比 @Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 Spring 容器时，则只能通过 @Bean 来实现

### Mybatis

#### #{} 和 ${} 的区别是什么

* `${}`是 Properties 文件中的变量占位符，它可以用于标签属性值和 sql 内部，属于静态文本替换，比如${driver}会被静态替换为`com.mysql.jdbc.Driver`
* `#{}`是 sql 的参数占位符，MyBatis 会将 sql 中的`#{}`替换为? 号，在 sql 执行前会使用 PreparedStatement 的参数设置方法，按序给 sql 的? 号占位符设置参数值，比如 ps.setInt(0, parameterValue)，`#{item.name}` 的取值方式为使用反射从参数对象中获取 item 对象的 name 属性值，相当于 `param.getItem().getName()`


## JavaWeb

### get、post 请求的区别

* GET 和 POST 是 HTTP 协议中的两种发送请求的方法。由于 HTTP 的底层是 TCP/IP。所以 GET 和 POST 的底层也是 TCP/IP 所以 GET 和 POST 在本质上没什么区别
* (两者之间最大的区别) GET 产生一个 TCP 数据包（浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）)；POST 产生两个 TCP 数据(浏览器先发送 header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据），但Firefox就只发送一次)。
* GET 是从服务器上获取数据(查询数据)，post 是向服务器传送数据(数据添加、修改、删除)。
* GET 把请求的数据放在 url 上面 即 http 的协议头上，post 把数据放在 http 的包体内(requrest body)（post比get安全）。
* Get 请求参数通过 url 传递，所以传送的参数是有长度限制的，post 请求方法 在request body 中，所以没有限制(get、post理论上是都没有长度限制的,get提交的数据最大是2k,限制实际上是取决于浏览器;post 实际上有限制 IIS4最大量为80KB,IIS5为100KB)。
* Get 在浏览器回退时是无害的，而 post 会再次请求提交 。
* Get 请求会被浏览器主动 cache，而 post 不会 除非手动设置。
* Get 请求只能进行 url 编码(ASCII字符)，而 post 支持多种编码方式
* post那么好为什么还用get ? get效率高!
* **GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，**可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签**。
* **POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。所以，**浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签**。

### Cookie 和 Session

* Cookie 和 Session 都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。
* **Cookie 一般用来保存用户信息** 比如 ① 我们在 Cookie 中保存已经登录过的用户信息，下次访问网站的时候页面可以自动帮你把登录的一些基本信息给填了；② 一般的网站都会有保持登录，也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③ 登录一次网站后访问网站其他页面不需要重新登录。
* **Session 的主要作用就是通过服务端记录用户的状态。** 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。
* Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。
* Cookie 存储在客户端中，而 Session 存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密，然后使用到的时候再去服务器端解密。

## JVM

### JVM 内存结构

#### 程序计数器

* 内部保存 JVM 中下一条所要执行的指令的**地址**
* 作用：
  * 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。
  * 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。
* 特点：
  * 是线程私有的
  * **不会存在内存溢出**，是 JVM 规范中唯一一个不出现 OOM (内存溢出) 的区域，所以这个空间不会进行 GC (垃圾回收)

#### 虚拟机栈

* 虚拟机栈的生命周期和线程相同，随着线程的创建而创建，随着线程的死亡而死亡，方法调用的数据需要通过栈进行传递，每一次方法调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。
* 每个栈由多个栈帧组成，对应着每次方法调用时所占用的内存，每个栈帧中存储着：
  * 局部变量表：存储方法里的 Java 基本数据类型以及对象的引用
  * 动态链接：也叫指向运行时常量池的方法引用
  * 方法返回地址：方法正常退出或者异常退出的定义
  * 操作数栈或表达式栈和其他一些附加信息
* 特点：
  * 是线程私有的
  * 栈内存**不需要进行 GC**，方法开始执行的时候会进栈，方法调用后自动弹栈，相当于清空了数据
  * 栈内存分配越大，可用的线程数越少（内存越大，每个线程拥有的内存越大）

#### 堆

是 JVM 内存中最大的一块，通过 new 关键字**创建的对象**都会被放在堆内存，由所有线程共享，由**垃圾回收器**管理的主要区域，堆中对象大部分都需要考虑线程安全的问题

#### 本地方法栈

* 本地方法栈是为虚拟机执行本地方法时提供服务的
* 本地方法被执行的时候，在本地方法栈也会创建一个栈帧
* 特点：
  * 是线程私有的

#### 方法区

* JVM 运行时数据区域的一块逻辑区域，是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、即时编译器编译后的代码等数据。
* 方法区是一个 JVM 规范，**永久代**( jdk1.8 以前)**与元空间**( jdk1.8 以后)都是其一种实现方式。
* 为了**避免方法区出现 OOM**，在 JDK8 中将堆内的方法区（永久代）移动到了本地内存上，重新开辟了一块空间，叫做元空间，元空间存储类的元信息，**静态变量和字符串常量池等放入堆中**。

#### 直接内存

* 直接内存是 Java 堆外、直接向系统申请的内存区间，不是虚拟机运行时数据区的一部分

### 对象创建的过程

1. 类加载检查

   虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。

2. 分配内存

   在**类加载检查**通过后，接下来虚拟机将为新生对象**分配内存**。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。

3. 初始化零值

   内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

4. 设置对象头

   初始化零值完成之后，**虚拟机要对对象进行必要的设置**，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 **这些信息存放在对象头中。** 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。

5. 执行 init 方法

   在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，`<init>` 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 `<init>` 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。

### JVM 垃圾回收

#### 判断对象是否可以回收

##### 引用计数法

* 给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的
* 缺点：无法解决循环引用问题，会引发内存泄露

##### 可达性分析算法

* 通过一系列的称为 **“GC Roots”** 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的，需要被回收。
* **GC Roots 对象：**
  - 虚拟机栈中局部变量表中引用的对象：各个线程被调用的方法中使用到的参数、局部变量等
  - 本地方法栈中引用的对象
  - 堆中类静态属性引用的对象
  - 方法区中的常量引用的对象
  - 字符串常量池（string Table）里的引用
  - 同步锁 synchronized 持有的对象

##### 引用分析

1. 强引用：

   这是使用最普遍的引用，比如 new 出来的对象，被强引用关联的对象不会被回收，只有所有 GCRoots 都不通过强引用引用该对象，才能被垃圾回收

   - 强引用可以直接访问目标对象
   - 虚拟机宁愿抛出 OOM 异常，也不会回收强引用所指向对象
   - 强引用可能导致**内存泄漏**

2. 软引用：

   被软引用关联的对象只有在内存不够的情况下才会被回收

   * 仅有软引用引用该对象时（可能有强引用，一个对象可以被多个引用），在垃圾回收后，内存仍不足时会再次出发垃圾回收，回收软引用对象
   * 配合引用队列来释放软引用自身，在构造软引用时，可以指定一个引用队列，当软引用对象被回收时，就会加入指定的引用队列，通过这个队列可以跟踪对象的回收情况
   * 软引用通常用来实现内存敏感的缓存，比如高速缓存就有用到软引用；如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时不会耗尽内存

3. 弱引用：

   被弱引用关联的对象一定会被回收，只能存活到下一次垃圾回收发生之前

   - 仅有弱引用引用该对象时，在垃圾回收时，无论内存是否充足，都会回收弱引用对象
   - 配合引用队列来释放弱引用自身
   - WeakHashMap 用来存储图片信息，可以在内存不足的时候及时回收，避免了 OOM

4. 虚引用：

   称为幽灵引用或者幻影引用，是所有引用类型中最弱的一个

   * 一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象
   * 为对象设置虚引用的唯一目的是在于**跟踪垃圾回收过程**，能在这个对象被回收时收到一个系统通知
   * 必须配合引用队列使用，主要配合 ByteBuffer 使用，被引用对象回收时会将虚引用入队，由 Reference Handler 线程调用虚引用相关方法释放直接内存

5. 终结器引用：

#### 垃圾收集算法

##### 分代收集理论

![img](https://img-blog.csdnimg.cn/img_convert/bbff960f14fe80586e6cb6cb7f099dd9.png)新创建的对象都被放在了**新生代的伊甸园**中![img](https://img-blog.csdnimg.cn/img_convert/c7f0e45c15aaec8ee235469890b41ce1.png)当伊甸园中的内存不足时，就会进行一次垃圾回收，这时的回收叫做 **Minor GC**，Minor GC 会将**伊甸园和幸存区FROM**存活的对象**先**复制到 **幸存区 TO**中， 并让其**寿命加1**，再**交换两个幸存区**![img](https://img-blog.csdnimg.cn/img_convert/91ad6e095c4ea702479580266de96b0c.png)![img](https://img-blog.csdnimg.cn/img_convert/b77a10379efca82c1850159ca6b59b15.png)![img](https://img-blog.csdnimg.cn/img_convert/edbcc7e59b7e6fd970ff0d70de022e9a.png)再次创建对象，若新生代的伊甸园又满了，则会再次触发 Minor GC（会触发 stop the world，暂停其他用户线程，只让垃圾回收线程工作)，这时不仅会回收伊甸园中的垃圾，还会回收幸存区中的垃圾，再将活跃对象复制到幸存区TO中。回收以后会交换两个幸存区，并让幸存区中的对象寿命加1
![img](https://img-blog.csdnimg.cn/img_convert/9ca82978e4f0106ebe1d4af3893ac6a1.png)如果幸存区中的对象的**寿命超过某个阈值**（最大为15，4bit)，就会被**放入老年代**中![img](https://img-blog.csdnimg.cn/img_convert/7502d4249dfc4917981c69cea68ae6a3.png)如果新生代老年代中的内存都满了，就会先触发Minor GC，再触发 **Full GC**，扫描**新生代和老年代中**所有不再使用的对象并回收

##### GC 分析

* 大对象处理策略
  * 当遇到一个较大的对象时，就算新生代的伊甸园为空，也无法容纳该对象时，会将该对象直接进升为老年代
* 线程内存溢出
  * 某个线程的内存溢出了而抛异常（out of memory），不会让其他的线程结束运行
  * 这是因为当一个线程**抛出 OOM 异常后**，**它所占据的内存资源会全部被释放掉**，从而不会影响其他线程的运行，**进程依然正常**

##### 标记-清除算法

* 首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。
* 算法缺点：
  - 标记和清除过程效率都不高
  - 会产生大量不连续的内存碎片，导致无法给大对象分配内存，需要维护一个空闲链表

##### 标记-复制算法

* 它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。
* 算法优点： 
  - 没有标记和清除过程，实现简单，运行高效
  - 复制过去以后保证空间的连续性，不会出现“碎片”问题。
* 算法缺点：
  - 主要不足是**只使用了内存的一半**
  - 对于 G1 这种分拆成为大量 region 的 GC，复制而不是移动，意味着 GC 需要维护 region 之间对象引用关系，不管是内存占用或者时间开销都不小

##### 标记-整理算法

* 标记整理算法是在标记清除算法的基础之上，做了优化改进的算法，在清理阶段，并不是简单的直接清理可回收对象，而是**将存活对象都向内存另一端移动**，然后清理边界以外的垃圾，从而**解决了碎片化**的问题

**在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。**

#### 垃圾收集器

##### Serial 收集器

* 一个单线程收集器，它的 **“单线程”** 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ **"Stop The World"** ），直到它收集结束。
* 新生代采用标记-复制算法，老年代采用标记-整理算法。

##### Parallel 收集器

* Parallel 收集器关注点是吞吐量

##### CMS 收集器

* CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用，第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。
* 优点：
  * **并发收集、低停顿**
* 缺点：
  * **对 CPU 资源敏感；**
  * **无法处理浮动垃圾；**
  * **它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。**

##### G1 收集器

* G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器。以极高概率满足 GC 停顿时间要求的同时，还具备高吞吐量性能特征，**响应与吞吐量兼顾**
* 特点：
  * **并行与并发**：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。
  * **分代收集**：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。
  * **空间整合**：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。
  * **可预测的停顿**：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。
* **G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region (这也就是它的名字 Garbage-First 的由来)** 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。

### 类加载机制

#### 类加载过程

![](https://seazean.oss-cn-beijing.aliyuncs.com/img/Java/JVM-类的生命周期.png)

#### 双亲委派模型

* 每一个类都有一个对应它的类加载器。系统中的 ClassLoader 在协同工作的时候会默认使用 **双亲委派模型** 。即在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，首先会把该请求委派给父类加载器的 `loadClass()` 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 `BootstrapClassLoader` 中。当父类加载器无法处理时，才由自己来处理。当父类加载器为 null 时，会使用启动类加载器 `BootstrapClassLoader` 作为父类加载器。
* 优点：
  * 可以避免某一个类被重复加载，当父类已经加载后则无需重复加载，保证全局唯一性
  * Java 类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一
  * 保护程序安全，防止类库的核心 API 被随意篡改。
    * 如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 `java.lang.Object` 类的话，那么程序运行的时候，系统就会出现多个不同的 `Object` 类。
* 缺点：
  * 检查类是否加载的委托过程是单向的，这个方式虽然从结构上看比较清晰，使各个 ClassLoader 的职责非常明确，但**顶层的 ClassLoader 无法访问底层的 ClassLoader 所加载的类**（可见性）

#### 破坏双亲委派模型

* 自定义 ClassLoader
  * 如果不想破坏双亲委派模型，只需要重写 findClass 方法
  * 如果想要去破坏双亲委派模型，需要去重写 loadClass 方法
* 引入线程**上下文类加载器**
* 实现程序的动态性

## 设计模式

### 代理模式

使用代理对象来代替对真实对象的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。代理模式主要作用是扩展目标对象的功能，比如说在目标对象的某个方法执行前后你可以增加一些自定义的操作。

#### 静态代理

#### 动态代理

##### JDK 动态代理

##### CGLIB 动态代理

##### 两者区别

* **JDK 动态代理只能代理实现了接口的类或者直接代理接口，而 CGLIB 可以代理未实现任何接口的类。** 另外， CGLIB 动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。
* JDK 动态代理是实现了被代理对象的接口，CGLIB 是继承了被代理对象
* 就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显。

### 单例模式

在我们的系统中，有一些对象其实我们只需要一个，比如说：线程池、缓存、对话框、注册表、日志对象、充当打印机、显卡等设备驱动程序的对象。事实上，这一类对象只能有一个实例，如果制造出多个实例就可能会导致一些问题的产生，比如：程序的行为异常、资源使用过量、或者不一致性的结果。

**使用单例模式的好处:**

- 对于频繁使用的对象，可以省略创建对象所花费的时间，这对于那些重量级对象而言，是非常可观的一笔系统开销；
- 由于 new 操作的次数减少，因而对系统内存的使用频率也会降低，这将减轻 GC 压力，缩短 GC 停顿时间。

#### 饿汉式

饿汉式是指在第一次加载类的时候，就实例化对象，也就是在单例类的内部将类实例化，**无论单线程或是多线程，饿汉式都能保证单一实例**

```java
class SingleTon {
    // 注意需要使用 static 和 final 修饰 并在内部直接实例化
	private static final SingleTon singleTon = new SingleTon();
    // 定义 private 私有构造器，表示只在类内部使用，亦指单例的实例只能在单例类内部创建
    private SingleTon() {
    }
    // 返回内部的 singleTon 实例
    public static SingleTon getSingleTon() {
        return singleTon;
    }
    // 如果该对象被用于序列化，可以保证对象在序列化前后保持一致
    public Object readResolve() {
        return singleTon;
    }
}
```

#### 懒汉式

懒汉式是指不在类加载时就创建类的单例，而是在第一次使用实例的时候再创建，多线程情况下不能保证线程安全

* 单线程

  ```java
  class SingleTon() {
      private static SingleTon singleTon = null;
      private SingleTon() {
      }
      // 如果 singleTon 为空则进行实例化
      public static SingleTon getSingleTon() {
          if (singleTon == null) {
              singleTon = new SingleTon();
          }
          return singleTon;
      }
      // 如果该对象被用于序列化，可以保证对象在序列化前后保持一致
      public Object readResolve() {
          return singleTon;
      }
  }
  ```

* 多线程 双重检查锁(DCL)

  ```java
  class SingleTon() {
      // 使用 volatile 使主内存中的 singleTon 对线程可见
      private volatile static SingleTon singleTon = null;
      private SingleTon() {
      }
      // 如果 singleTon 为空则进行实例化
      public static SingleTon getSingleTon() {
          if (getSingleTon() == null) {
              // 如果对象为空，则是第一次实例化，这时锁住对象
              synchronized(singleTon) {
                  // 第二次判断是否为空，防止多线程操作时，在执行第一次判断后另一个线程完成了实例化
                  if (singleTon == null) {
              		singleTon = new SingleTon();
                  }
              }
          }
          return singleTon;
      }
      // 如果该对象被用于序列化，可以保证对象在序列化前后保持一致
      public Object readResolve() {
          return singleTon;
      }
  }
  ```

# 计算机网络

## OSI 七层模型

**OSI 七层模型** 是国际标准化组织提出一个网络分层模型，其大体结构以及每一层提供的功能如下图所示：![osi七层模型](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/osi%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B.png)

## TCP/IP 四层模型

**TCP/IP 四层模型** 是目前被广泛采用的一种模型，我们可以将 TCP / IP 模型看作是 OSI 七层模型的精简版本

对于同一台设备上的进程间通信，有很多种方式，比如有管道、消息队列、共享内存、信号等方式，而对于不同设备上的进程间通信，就需要网络通信，而设备是多样性的，所以要兼容多种多样的设备，就协商出了一套**通用的网络协议**。

### 应用层

* 应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP，应用层是不用去关心数据是如何传输的，人们电脑或手机使用的应用软件都是在应用层实现。

### 传输层

* 应用层的数据包会传给传输层，传输层为应用层提供网络支持的，**主要任务就是负责向两台终端设备进程之间的通信提供通用的数据传输服务**。
* 在传输层会有两个传输协议，分别是 TCP 和 UDP
  * TCP 的全称叫传输控制协议（*Transmission Control Protocol*），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。
  * UDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情。

### 网络层

* **网络层负责为分组交换网上的不同主机提供通信服务。** 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报，简称数据报。
* **选择合适的路由，使源主机运输层所传下来的分组，能通过网络层中的路由器找到目的主机。**

### 网络接口层

* 在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。
* 为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。

## 在浏览器中输入 url 地址 ->> 显示主页的过程

* 解析输入的 url 地址，确定 Web 服务器和文件名，生成 HTTP 请求信息
* 根据 DNS 服务器，查询发送对象的服务器域名对应的 IP 地址，有缓存先查缓存，浏览器缓存 → 路由去缓存 → DNS 缓存
* 通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的**协议栈**。
* 在 HTTP 传输数据之前，首先需要通过**三次握手**，与 TCP 建立连接，**保证双方都有发送和接收的能力**。
* 服务器处理请求并返回 HTTP 报文
* 浏览器解析渲染页面

## 应用层常见的协议

* HTTP：超文本传输协议
* SMTP：简单邮件传输协议
* POP3/IMAP：邮件接收的协议
* FTP：文件传输协议
* Telnet：远程登陆协议（由于所有数据均以明文形式发送，有潜在的安全风险）
* SSH：安全的网络传输协议

## HTTP

### HTTP 基本概念

* 超文本传输协议，HTTP 协议就是用来规范超文本的传输，超文本，也就是网络上的包括文本在内的各式各样的消息，具体来说，主要是来规范浏览器和服务器端的行为的。
* HTTP 是一个无状态（stateless）协议，也就是说服务器不维护任何有关客户端过去所发请求的消息，利用 Cookie 和 Session 来保存用户的状态。

### 常见的状态码

![状态码](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/%E7%8A%B6%E6%80%81%E7%A0%81.png)

### HTTP 与 HTTPS

* **HTTP** 是应用层协议，它以 TCP（传输层）作为底层协议，默认端口为 80. **HTTPS** 协议是 HTTP 的加强安全版本。HTTPS 是基于 HTTP 的，也是用 TCP 作为底层协议，并额外使用 SSL/TLS 协议用作加密和安全认证。默认端口号是 443. 。
* HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
* HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

### HTTP 1.0 和 HTTP 1.1

* **连接方式** : HTTP 1.0 为短连接，HTTP 1.1 支持长连接，改善了短连接造成的性能开销。
* **状态响应码** : HTTP/1.1中新加入了大量的状态码，光是错误响应状态码就新增了24种。比如说，`100 (Continue)`——在请求大资源前的预热请求，`206 (Partial Content)`——范围请求的标识码，`409 (Conflict)`——请求与当前资源的规定冲突，`410 (Gone)`——资源已被永久转移，而且没有任何已知的转发地址。
* **缓存处理** : 在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。
* **带宽优化及网络连接的使用** :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
* **Host头处理** : HTTP/1.1在请求头中加入了`Host`字段。
* **支持管道网络传输**：只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

### HTTP 2.0

* **安全性**：HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的
* **头部压缩**：如果你同时发出多个请求，他们的头是一样的或是相似的，那么，HTTP/2 协议会帮你**消除重复的部分**。
* **二进制格式**：HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了**二进制格式**，头信息和数据体都是二进制，并且统称为帧（frame）：**头信息帧（Headers Frame）和数据帧（Data Frame）**，增加了计算机数据传输的效率。
* **数据流**：HTTP/2 对每个数据包做标记，指出它属于哪个回应，在 HTTP/2 中每个请求或相应的所有数据包，称为一个数据流，每个数据流都标记着一个独一无二的编号，可以并发不同的 Stream。
* **多路复用**：HTTP/2 是可以在**一个连接中并发多个请求或回应，而不用按照顺序一一对应**，移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，**降低了延迟，大幅度提高了连接的利用率**。
* **服务器推送**：一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动**向客户端发送消息。

## TCP

### TCP 三次握手与四次挥手

* 三次握手：
  * 客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1` ，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态。
  * 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。
  * 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 `ESTABLISHED` 状态。
  * 服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。
* 为什么要三次握手？
  * 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
  * 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。
  * 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。因此，需要三次握手才能确认双方的接收与发送能力是否正常。
* 四次挥手：
  * 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
  * 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。
  * 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
  * 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。（比三次握手多的一次，用来传输数据）
  * 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
  * 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSED` 状态，至此服务端已经完成连接的关闭。
  * 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSED` 状态，至此客户端也完成连接的关闭。
* 为什么要四次挥手？
  * 任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了 TCP 连接。

### 长连接和短连接

* 长连接
  * 连接 → 传输数据 → 保持连接 → 传输数据 → ....... → 关闭连接
  * 长连接指建立 TCP 连接后不管是否使用都保持连接，但安全性较差
  * 长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况。每个 TCP 连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，次处理时直接发送数据包就OK了，不用建立 TCP 连接。例如：数据库的连接用长连接， 如果用短连接频繁的通信会造成 socket 错误，而且频繁的 socket 创建也是对资源的浪费
* 短连接
  * 连接 → 传输数据 → 关闭连接 
  * 短连接是指通信双方有数据交互时，就建立一个 TCP 连接，数据发送完成后，则断开此 TCP 连接
  * WEB网站的http服务一般都用连接，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁地成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连接好

### TCP 协议是如何保证可靠传输的

1. 应用数据被分割成 TCP 认为最适合发送的数据块。
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
3. **校验和：** TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
4. TCP 的接收端会丢弃重复的数据。
5. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. **拥塞控制：** 当网络拥塞时，减少数据的发送。
7. **ARQ 协议：** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
8. **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

#### 重传机制

* 超时重传：在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据
* 快速重传：收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。
* SACK 方法：在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。
* Duplicate SACK：**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

#### 滑动窗口和流量控制

* **TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。** 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

#### 拥塞控制

* 若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。
* **拥塞控制**是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，**流量控制**往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。
* 为了进行拥塞控制，TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。TCP 的拥塞控制采用了四种算法，即 **慢开始** 、 **拥塞避免** 、**快重传** 和 **快恢复**。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。
  - **慢开始：** 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍。
  - **拥塞避免：** 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送放的 cwnd 加 1.
  - **快重传与快恢复：** 在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。

### TCP 和 UDP 

* **UDP** 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 却是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等
* **TCP** 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP 的可靠体现在 TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。

## DNS

* DNS 可以将域名网址自动转换为具体的 IP 地址
* DNS 域名解析过程：
  * 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。
  * 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。
  * 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”
  * 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？”
  * 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。
  * 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。
  * 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
  * 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。

# MySQL

## SQL 语句 在 MySQL 中的执行过程

![img](https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png)

* 连接器：主要负责用户登录数据库，进行用户的身份认证，包括校验账户密码，权限等操作
* 查询缓存(MySQL 8.0 版本后移除)：查询缓存主要用来缓存我们所执行的 SELECT 语句以及该语句的结果集，由于只要对一个表进行更新，缓存就会失效，所以 MySQL 缓存失效出现得十分频繁，所以 MySQL 在 8.0 版本后移除了它
* 分析器：分析器主要是用来分析 SQL 语句是来干嘛的
* 优化器：优化器的作用就是它认为的最优的执行方案去执行，比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等
* 执行器：执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，返回接口执行的结果

## 索引

索引的作用就相当于目录的作用。索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有：B 树， B+树和 Hash。

### 索引的优缺点

**优点** ：

- 使用索引可以大大加快 数据的检索速度（大大减少检索的数据量）, 这也是创建索引的最主要的原因。
- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。

**缺点** ：

- 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。
- 索引需要使用物理文件存储，也会耗费一定空间。

大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升。

### 适合建索引的字段

* 表的主键和外键
* 数据量大，且查询比较频繁的字段
* 常作为查询条件(where),排序(order by)，分组(group by)操作的字段建立索引
* 选择区分度高的列作为索引
* 索引应该建立在小字段上，对于大的文本字段不要建立索引

### 索引的底层数据结构

#### 哈希表

* **Hash 索引不支持顺序和范围查询**，只适用于等值查询的场景，所以 MySQL 没有使用其作为索引的数据结构

#### B 树 & B+树

* 区别：

  * B 树，每个节点都存储 key 和 data，所有节点组成这棵树，并且叶子节点指针为 null，叶子结点不包含任何关键字信息。
  * B+ 树，所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接，所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (而 B 树的非终节点也包含需要查找的有效信息)

* 为什么说 B+ 比 B 树更适合实际应用中操作系统的文件索引和数据库索引？

  * 磁盘读写代价更低

    B+ 的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说 IO 读写次数也就降低了。

  * 查询效率更加稳定

    由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。

### 聚集索引和非聚集索引

#### 聚集索引

* 聚集索引**表记录的排列顺序和索引的排列顺序一致，所以查询效率快，**只要找到第一个索引值记录，其余就连续性的记录在物理也一样连续存放。聚集索引对应的缺点就是修改慢，因为为了保证表中记录的物理和索引顺序一致，在记录插入的时候，会对数据页重新排序。
* 优点：
  * 查询效率高，表记录的排列顺序和索引的排列顺序一致，定位到了索引，即定位到了数据
* 缺点：
  * **依赖于有序的数据** ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。
  * **更新代价大** ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改，而且聚集索引的叶子节点还存放着数据，修改代价肯定是较大的，所以对于主键索引来说，主键一般都是不可被修改的。

#### 非聚集索引

* 非聚集索引即索引结构和数据分开存放的索引，比如二级索引
* 优点：
  * **更新代价比聚集索引要小** 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的
* 缺点：
  * 会产生二次查询，即回表，当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询对应的数据

### 一些索引优化的方法（联合索引）

* 覆盖索引：如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果，减少IO磁盘读写读取正行数据
* 最左前缀：联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符
  * 最左前缀匹配原则指的是，在使用联合索引时，**MySQL** 会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配，如果查询条件中存在与联合索引中最左侧字段相匹配的字段，则就会使用该字段过滤一批数据，直至联合索引中全部字段匹配完成
* 联合索引：根据创建联合索引的顺序，以最左原则进行where检索，比如（age，name）以age=1 或 age=1 and name=‘张三’可以使用索引，单以name=‘张三’ 不会使用索引，考虑到存储空间的问题，还请根据业务需求，将查找频繁的数据进行靠左创建索引。
* 索引下推：like 'hello%’and age >10 检索，MySQL5.6版本之前，会对匹配的数据进行回表查询。5.6版本后，会先过滤掉age<10的数据，再进行回表查询，减少回表率，提升检索速度

### 索引失效的场景

* 模糊查询时 like 以 % 开头
* OR 前后查询语句只有一个是索引，只有当or左右查询字段均为索引时，才会生效
* 在索引列上使用 IS NULL 或 IS NOT NULL操作
* 在索引字段上使用not，<>，!=
* 当全表扫描速度比索引速度快时，mysql会使用全表扫描，此时索引失效

## MySQL 三大日志

### redo log

* `redo log`（重做日志）是物理日志，记录的是“在某个数据页上做了什么修改”
* `redo log`（重做日志）是`InnoDB`存储引擎独有的，它让`MySQL`拥有了崩溃恢复能力。比如 `MySQL` 实例挂了或宕机了，重启时，`InnoDB`存储引擎会使用`redo log`恢复数据，保证数据的持久性与完整性。
* `MySQL` 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 `Buffer Pool` 中。后续的查询都是先从 `Buffer Pool` 中找，没有命中再去硬盘加载，减少硬盘 `IO` 开销，提升性能。更新表数据的时候，也是如此，发现 `Buffer Pool` 里存在要更新的数据，就直接在 `Buffer Pool` 里更新。然后会把“在某个数据页上做了什么修改”记录到重做日志缓存（`redo log buffer`）里，接着刷盘到 `redo log` 文件里。

### binlog

* `binlog` 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于`MySQL Server` 层，不管用什么存储引擎，只要发生了表数据更新，都会产生 `binlog` 日志，不是`InnoDB`存储引擎独有的
* `MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性，`binlog`会记录所有涉及更新数据的逻辑操作，并且是顺序写。
* `binlog`的写入时机也非常简单，事务执行过程中，先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到`binlog`文件中。

### undo log

* undo log 回滚日志是 InnoDB 引擎独有的，保证事务的原子性
* 我们知道如果想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行**回滚**，在 MySQL 中，恢复机制是通过 **回滚日志（undo log）** 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用 **回滚日志** 中的信息将数据回滚到修改之前的样子即可！并且，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。

MySQL InnoDB 引擎使用 **redo log(重做日志)** 保证事务的**持久性**，使用 **undo log(回滚日志)** 来保证事务的**原子性**。`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性。

## 事务

事务是逻辑上的一组操作，要么都执行，要么都不执行。

### 事务的特性（ACID）

* **原子性：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
* **一致性：** 执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；
* **隔离性：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
* **持久性：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

### 并发事务带来的问题

* **脏读（Dirty read）:** 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。

* **丢失修改（Lost to modify）:** 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。

* **不可重复读（Unrepeatableread）:** 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。

* **幻读（Phantom read）:** 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

* **不可重复度和幻读区别：**

  不可重复读的重点是修改，幻读的重点在于新增或者删除。

### 事务隔离级别

* **读未提交：**最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。

* **读已提交：**允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。

* **可重复读：**对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。

* **串行化：**最高的隔离级别，在这个隔离级别下，不会产生任何异常。并发的事务，就像事务是在一个个按照顺序执行一样

  | 事务隔离级别 | 脏读 | 不可重复读 | 幻读 |
  | ------------ | ---- | ---------- | ---- |
  | 读未提交     | √    | √          | √    |
  | 读已提交     | ×    | √          | √    |
  | 可重复读     | ×    | ×          | √    |
  | 串行化       | ×    | ×          | ×    |

* MySQL InnoDB 存储引擎的默认支持的隔离级别是可重复读，在分布式事务下一般为串行化

* 解决幻读的方法：一个事务在操作某张表数据的时候，另外一个事务不允许新增或者删除这张表中的数据

  * 将事务隔离级别调整为串行化
  * 在可重复读的事务级别下，给事务操作的这张表添加表锁
  * 在可重复读的事务级别下，给事务操作的这张表添加 `Next-Key Locks`：行锁 + 间隙锁

## 存储引擎

### InnoDB、MyISAM 两大存储引擎的比较

* InnoDB 支持事务，MyISAM 不支持，因此 InnoDB 适合频繁修改以及涉及到安全性较高的应用，MyISAM 适合查询以及插入为主的应用。
* InnoDB 支持外键，MyISAM 不支持。
* InnoDB 支持行锁和表级锁，默认为行级锁，MyISAM 不支持行锁。
* MyISAM 不支持数据库异常崩溃后的安全恢复，而 InnoDB 支持（ **redo log(重做日志)** 保证事务的**持久性**，使用 **undo log(回滚日志)** 来保证事务的**原子性**）。
* MyISAM 不支持 MVCC，而 InnoDB 支持，MVCC 可以看作是行级锁的一个升级，可以有效减少加锁操作，提高性能。

## MySQL 中的锁

**MySQL有三种锁的级别：**全局锁、表级级、行级锁。

- **全局锁**：对整个数据库实例加锁。提供加全局读锁的方法：Flush tables with read lock(FTWRL)，这个命令可以使整个库处于只读状态。**使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。**使用场景是**全库逻辑备份**。
  MySQL提供加全局读锁的方法：Flush tables with read lock(FTWRL)
- **表级锁**：MySQL里面表级锁有两种，一种是表锁，一种是元数据锁(meta data lock,MDL)，锁住整个表，其中 MDL 不需要显式使用，在访问一个表的时候会被自动加上。**Server 层面实现的！！！！**
- **行级锁**：存储引擎级别实现

### MVCC

* MVCC  为多版本并发控制，一种用来解决读-写冲突的无锁并发控制机制。读取数据时通过一种类似快照的方式将数据保存下来，解决了读锁与写锁之间的冲突问题，不同的事务 session 会看到自己特定版本的数据和版本链
* MVCC 在读已提交（Read Committed）和可重复读（Repeatable Read）隔离级别下起作用
* 实现原理
  * 每一行记录都有三个隐藏列
    * `DB_TRX_ID（6 字节）`：表示最后一次插入或更新该行的事务 id
    * `DB_ROLL_PTR（7 字节）`： 回滚指针，指向该行的 `undo log` 。如果该行未被更新，则为空。
    * `DB_ROW_ID（6 字节）`：如果没有设置主键且该表没有唯一非空索引时，`InnoDB` 会使用该 id 来生成聚簇索引
  * 基于 undo log 的版本链
    * 每行数据的隐藏列中包含了指向 undo log 的指针，而每条 undo log 也会指向更早版本的 undo log ，从而形成一条版本链
    * 在 RU 隔离级别下，直接读取版本的最新记录就 OK，对于 SERIALIZABLE 隔离级别，则是通过加锁互斥来访问数据，因此不需要 MVCC 的帮助。因此 MVCC 运行在 RC 和 RR 这两个隔离级别下，当 InnoDB 隔离级别设置为二者其一时，在 SELECT 数据时就会用到版本链
  * ReadView
    * 主要是用来做可见性判断，里面保存了 “当前对本事务不可见的其他活跃事务”
    * 在 `InnoDB` 存储引擎中，创建一个新事务后，执行每个 `select` 语句前，都会创建一个快照（Read View），**快照中保存了当前数据库系统中正处于活跃（没有 commit）的事务的 ID 号**。
    * 通过隐藏列和版本链，MySQL 可以将数据恢复到指定版本，但是具体要恢复到哪个版本，则需要根据ReadView 来确定。所谓 ReadView，是指事务（记做事务A）在某一时刻给整个事务系统（trx_sys）打快照，之后再进行读操作时，会将读取到的数据中的事务 id 与 trx_sys 快照比较，从而判断数据对该 ReadView 是否可见，即对事务A是否可见。
    * RC 在每一次 SELECT 语句前都会生成一个 ReadView，事务期间会更新，因此在其他事务提交前后所得到的 m_ids 列表可能发生变化，使得先前不可见的版本后续又突然可见了。而 RR 只在事务的第一个 SELECT 语句时生成一个 ReadView，事务操作期间不更新。

## 优化查询

### 排查出查询缓慢的 sql 语句

* 开启慢查询日志，MySQL 的慢查询日志是 MySQL 提供的一种日志记录，它用来记录在 MySQL 中响应时间超过阀值的语句
* 使用 explain 命令，explain 显示了 MySQL 如何使用索引来处理 select 语句以及连接表，可以帮助选择更好的索引和写出更优化的查询语句

## drop , delete 与 truncate 的区别

* drop 直接删掉表
* delete 删除表中数据，可以在后面添加 where 字句
* truncate 删除的是表中的数据，再插入数据时自增长的数据 id 又重新从 1 开始

## char 和 varchar

* char 是一种固定长度的类型，无论储存的数据有多少都会固定长度，如果插入的长度小于定义长度，则可以用空格进行填充，会浪费空间
* varchar是一种可变长度的类型，当插入的长度小于定义长度时，插入多长就存多长，更加节省空间
* char 最大长度是 255 字符，varchar 最大长度是 65535 个字节

# Redis

## Redis 为什么用单线程不用多线程？

* Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程，但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的
* 多线程的缺点：
  * 单线程编程容易并且更容易维护；
  * Redis 的性能瓶颈不在 CPU ，主要在内存和网络；
  * 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能，**多线程编程模式面临的共享资源的并发访问控制问题**。

## Redis 为什么这么快？

* Redis 是**内存**数据库，所有操作都在内存上完成，相较于在磁盘上读取数据的 MySQL 等关系型数据库，内存的访问速度远远大于磁盘的访问速度
* 高效的**数据结构**，例如哈希表和跳表
* 采用了**多路复用机制**，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率
  * 一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制
  * 内核可同时监听多个监听套接字和多个已连接套接字
  * 一旦内核监听到套接字上有数据返回，立刻交给 Redis 线程处理数据
  * Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。

## 数据结构

Redis 是一种键值型数据库

### 键和值之间的数据结构

* Redis 使用了一个哈希表来保存所有键值对，哈希表其实就是一个数组，数组的每个元素称为一个哈希桶，哈希桶中的元素保存的并不是值本身，而是指向具体值的指针
* 好处是用 O(1) 的时间复杂度来快速查找到键值对，但有时往 Redis 中写入大量数据后，操作会突然变慢，这是由于**哈希表的冲突问题和 rehash 可能带来的操作阻塞**
* 和 HashMap 类似，为了解决哈希冲突，使用拉链法，担当一条哈希链越来越长，那查询的效率也会变低，所以 Redis 会对哈希表进行 **rehash** 操作，为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash
  * 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
  * 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；
  * 释放哈希表 1 的空间，原来的哈希表 1 留作下一次 rehash 扩容备用
* **渐进 rehash**
  * 第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries
  * 解决了在 rehash 的拷贝大量数据操作时造成 Redis 线程阻塞的问题

### 值的数据结构

![img](https://static001.geekbang.org/resource/image/82/01/8219f7yy651e566d47cc9f661b399f01.jpg)

#### String

*  Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 **简单动态字符串**
* 相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)），除此之外，Redis 的简单动态字符串 API 是安全的，不会造成缓冲区溢出

#### List

* Redis 的 list 的实现为一个**双向链表**，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销

#### Hash

* hash 是一个 string 类型的 field 和 value 的映射表，**特别适合用于存储对象**，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值

#### Set

* set 类似于 Java 中的 `HashSet` 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作

#### SortedSet

* 和 set 相比，SortedSet 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体
* a

#### BitMap

* 

#### 压缩列表

* 压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束
* 查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 

#### 跳表

* 跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位

## 持久化

### AOF 日志

* 写后日志，Redis 是先执行命令，把数据写入内存，然后再记录 Redis 收到的每一条命令
  * 先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错，可以避免出现记录错误命令的情况
  * 在命令执行后才记录日志，所以**不会阻塞当前的写操作**
* 随着接收的写命令越来越多，AOF 文件会越来越大。这也就意味着，我们一定要小心 AOF 文件过大带来的性能问题，所以需要进行 **AOF 重写机制**
  * 在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令，在重写的时候，是根据这个键值对当前的最新状态，为它生成对应的写入命令
  * AOF 重写不会阻塞，因为重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降

### RDB 快照

* 和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复，避免了 AOF 需要顺序、逐一重新执行操作命令带来的低效性能问题
* RDB 的执行频率很重要，频繁快照仍然是不太能接受的，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。
* 混合使用 RDB 和 AOF，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能

## 集群

**TODO**

# GIT

# LINUX

## 基本操作

* cd 进入目录
* ls 查看当前目录下有什么文件
* mkdir 创建文件夹 rmdir 删除文件夹
* **top 命令**查看进程 id **kill 命令**杀死进程
* ifconfig 显示所有网络接口的配置信息
* ps 查看当前系统进程使用情况
  * ps -aux 查看进程的 CPU 占用率和内存占用率
  * ps -ef 查看进程的父进程 ID

* netstat  显示网络状态和端口占用信息
  * netstat -tunlp | grep 端口号 查看端口状态

* du 查看文件和目录占用的磁盘空间
* df 查看磁盘空间使用情况



